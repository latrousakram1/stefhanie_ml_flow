# -*- coding: utf-8 -*-
"""Untitled-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1orLHe0eb91W6QgBAAd7JlCK59RDrTou9
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install --upgrade scikit-learn==1.5.2

# Commented out IPython magic to ensure Python compatibility.
# %pip install --upgrade numpy scipy

import pandas as pd
import numpy as np
import mlflow
import mlflow.sklearn

from sklearn.model_selection import TimeSeriesSplit
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

from sklearn.linear_model import LinearRegression, Ridge
from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor

"""- Charge toutes les librairies nécessaires : pandas/numpy pour manipuler les données, scikit-learn pour les modèles et pipelines, optuna pour l’optimisation, matplotlib/seaborn pour les graphiques.

"""

pip install mlflow

# 1) Chargement et renommage
df = pd.read_csv("/content/historique-consommation-secteur-activite-ra-mois.csv", sep=None, engine="python")
df = df.rename(columns={
    "﻿REGION_ADM_QC_TXT": "Région",
    "ANNEE_MOIS": "Date",
    "SECTEUR": "Secteur",
    "Total (kWh)": "Consommation_kWh"
})
df["Date"] = pd.to_datetime(df["Date"], errors="coerce")

"""- Lit le fichier CSV brut.
- Renomme les colonnes pour plus de clarté (Région, Date, Secteur, Consommation_kWh).
- Convertit la colonne Date en format datetime.

"""

# 2) Préparation et enrichissement
def enrich_features(df_raw):
    df = df_raw.copy()
    df = df[df["Secteur"].str.upper().str.contains("RÉSIDENTIEL")].sort_values(["Région","Date"])

    # Variables temporelles
    df["mois"] = df["Date"].dt.month
    df["annee"] = df["Date"].dt.year

    # Température simulée
    def simulate_temperature(month):
        return 7 + 18 * np.sin((month - 1) / 12 * 2 * np.pi)
    df["Température_moyenne"] = df["mois"].apply(simulate_temperature)

    # Tarifs saisonniers
    def tarif_saisonnier(mois):
        if mois in [12,1,2,3]:
            return 0.17
        elif mois in [6,7,8,9]:
            return 0.13
        else:
            return 0.15
    df["Tarif"] = df["mois"].apply(tarif_saisonnier)

    # Cible
    df["Montant_facture"] = df["Consommation_kWh"] * df["Tarif"]

    # Lags et moyenne mobile
    df["lag1"] = df.groupby("Région")["Consommation_kWh"].shift(1)
    df["lag3"] = df.groupby("Région")["Consommation_kWh"].shift(3)
    df["roll3"] = (
        df.groupby("Région")["Consommation_kWh"]
        .rolling(window=3, min_periods=1).mean()
        .reset_index(level=0, drop=True)
    )

    # Indicateur saison
    df["saison_froide"] = df["mois"].isin([12,1,2]).astype(int)

    # Interaction consommation × température
    df["Interaction_kWh_temp"] = df["Consommation_kWh"] * df["Température_moyenne"]

    # Nettoyage
    req = ["Consommation_kWh","lag1","lag3","roll3","Montant_facture"]
    df = df.dropna(subset=req)
    return df

df_prep = enrich_features(df)

"""- Filtre le secteur résidentiel.
- Ajoute des variables temporelles (mois, année).
- Simule une température moyenne par mois.
- Ajoute des tarifs saisonniers.
- Crée la cible Montant_facture.
- Ajoute des lags (valeurs passées), moyennes mobiles, indicateur saison froide, interactions consommation × température.
- Supprime les lignes incomplètes.

"""

# 3) Split temporel
def temporal_split(df, cutoff="2023-01-01"):
    cutoff = pd.Timestamp(cutoff)
    train = df[df["Date"] < cutoff]
    test  = df[df["Date"] >= cutoff]
    y_train = train["Montant_facture"]
    y_test  = test["Montant_facture"]
    X_train = train.drop(columns=["Montant_facture"])
    X_test  = test.drop(columns=["Montant_facture"])
    return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = temporal_split(df_prep)

"""- Sépare les données en train (avant 2023) et test (2023 et après).
- Permet de simuler une vraie prédiction sur des données futures.

"""

# 4) Préprocesseur
num_features = [
    "Consommation_kWh","lag1","lag3","roll3",
    "mois","annee","saison_froide",
    "Température_moyenne","Tarif","Interaction_kWh_temp"
]
cat_features = ["Région"]

preprocessor = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), num_features),
        ("cat", OneHotEncoder(handle_unknown="ignore"), cat_features),
    ]
)

"""- Définit les colonnes numériques et catégorielles.
- Applique un StandardScaler aux numériques et un OneHotEncoder aux régions.
- Tout est intégré dans un ColumnTransformer.

"""

# 5) Pipelines et modèles
def build_pipeline(model):
    return Pipeline([("prep", preprocessor), ("model", model)])

models = {
    "Linear": LinearRegression(),
    "Ridge": Ridge(alpha=1.0),
    "RandomForest": RandomForestRegressor(n_estimators=400, random_state=42),
    "GradientBoosting": HistGradientBoostingRegressor(max_iter=400, learning_rate=0.05, random_state=42),
}

"""- Définit 4 modèles : Linear, Ridge, RandomForest, GradientBoosting.
- Crée une fonction build_pipeline qui assemble le préprocesseur et le modèle.

"""

import seaborn as sns

import matplotlib.pyplot as plt

# 6) Évaluation
def evaluate(pipe, X_train, y_train, X_test, y_test, model_name=""):
    with mlflow.start_run(run_name=f"{model_name}_base"):
        pipe.fit(X_train, y_train)
        preds = pipe.predict(X_test)

        rmse = np.sqrt(mean_squared_error(y_test, preds))
        mae = mean_absolute_error(y_test, preds)
        r2 = r2_score(y_test, preds)

        mlflow.log_metric("RMSE", rmse)
        mlflow.log_metric("MAE", mae)
        mlflow.log_metric("R2", r2)

        return {"RMSE": rmse, "MAE": mae, "R²": r2}

results = []
for name, model in models.items():
    pipe = build_pipeline(model)
    scores = evaluate(pipe, X_train, y_train, X_test, y_test, model_name=name)
    results.append({"Modèle": name, **scores})

results_df = pd.DataFrame(results)
print("Résultats de base:\n", results_df)

sns.barplot(data=results_df, x="Modèle", y="MAE")
plt.title("Comparaison des MAE (modèles de base)")
plt.savefig("mae_comparaison_base.png")
mlflow.log_artifact("mae_comparaison_base.png")
plt.show()

"""- Entraîne chaque modèle sur le train.
- Prédit sur le test.
- Calcule RMSE, MAE, R².
- Stocke les résultats dans un tableau.
- Affiche un barplot comparatif des MAE

"""

from sklearn.model_selection import GridSearchCV

# Pipeline de base
pipe_rf = build_pipeline(RandomForestRegressor(random_state=42))
param_grid = {
    "model__n_estimators": [200, 400, 600],
    "model__max_depth": [None, 10, 20],
    "model__min_samples_split": [2, 5, 10],
}

grid_rf = GridSearchCV(pipe_rf, param_grid, cv=3, scoring="neg_mean_absolute_error", n_jobs=-1, verbose=2)
grid_rf.fit(X_train, y_train)
mlflow.end_run()

with mlflow.start_run(run_name="RandomForest_optimisé"):
    mlflow.log_params(grid_rf.best_params_)
    mlflow.log_metric("MAE", -grid_rf.best_score_)

"""- RandomForest : optimisation par GridSearchCV (grille exhaustive).

- Affiche les meilleurs paramètres et scores

"""

pip install  joblib scikit-learn optuna

import optuna
def objective(trial):
    params = {
        "max_iter": trial.suggest_int("max_iter", 200, 600),
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.2, log=True),
        "max_depth": trial.suggest_int("max_depth", 3, 15),
    }

    model = HistGradientBoostingRegressor(**params, random_state=42)
    pipe = build_pipeline(model)
    pipe.fit(X_train, y_train)
    preds = pipe.predict(X_test)
    return mean_absolute_error(y_test, preds)

study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=30)

with mlflow.start_run(run_name="GradientBoosting_optimisé"):
    mlflow.log_params(study.best_params)
    mlflow.log_metric("MAE", study.best_value)

"""- GradientBoosting : optimisation par Optuna (recherche bayésienne).
- Affiche les meilleurs paramètres et scores
"""

import mlflow
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# --- Récupération des résultats de base depuis results_df ---
def extract_base_scores(model_name):
    row = results_df.loc[results_df["Modèle"] == model_name]
    return row["MAE"].values[0], row["RMSE"].values[0], row["R²"].values[0]

mae_rf_base, rmse_rf_base, r2_rf_base = extract_base_scores("RandomForest")
mae_gb_base, rmse_gb_base, r2_gb_base = extract_base_scores("GradientBoosting")

# --- Résultats optimisés ---
# RandomForest optimisé
pipe_rf_best = grid_rf.best_estimator_
pipe_rf_best.fit(X_train, y_train)
pred_rf_opt = pipe_rf_best.predict(X_test)

mae_rf_opt = mean_absolute_error(y_test, pred_rf_opt)
rmse_rf_opt = np.sqrt(mean_squared_error(y_test, pred_rf_opt))
r2_rf_opt   = r2_score(y_test, pred_rf_opt)

# GradientBoosting optimisé
pipe_gb_best = build_pipeline(
    HistGradientBoostingRegressor(
        max_iter=study.best_params["max_iter"],
        learning_rate=study.best_params["learning_rate"],
        max_depth=study.best_params["max_depth"],
        random_state=42
    )
)
pipe_gb_best.fit(X_train, y_train)
pred_gb_opt = pipe_gb_best.predict(X_test)

mae_gb_opt = mean_absolute_error(y_test, pred_gb_opt)
rmse_gb_opt = np.sqrt(mean_squared_error(y_test, pred_gb_opt))
r2_gb_opt   = r2_score(y_test, pred_gb_opt)

# --- Création du DataFrame comparatif ---
df_perf = pd.DataFrame([
    {"Modèle": "RandomForest", "Version": "Base", "MAE": mae_rf_base, "RMSE": rmse_rf_base, "R²": r2_rf_base},
    {"Modèle": "RandomForest", "Version": "Optimisé", "MAE": mae_rf_opt, "RMSE": rmse_rf_opt, "R²": r2_rf_opt},
    {"Modèle": "GradientBoosting", "Version": "Base", "MAE": mae_gb_base, "RMSE": rmse_gb_base, "R²": r2_gb_base},
    {"Modèle": "GradientBoosting", "Version": "Optimisé", "MAE": mae_gb_opt, "RMSE": rmse_gb_opt, "R²": r2_gb_opt},
])

print("Tableau comparatif des performances :\n")
print(df_perf.round(4).to_string(index=False))

# --- Graphiques comparatifs avec log MLflow ---
sns.set(style="whitegrid")

with mlflow.start_run(run_name="Comparaison finale base vs optimisé"):
    for metric in ["MAE", "RMSE", "R²"]:
        plt.figure(figsize=(8,6))
        sns.barplot(data=df_perf, x="Modèle", y=metric, hue="Version", palette=["skyblue","salmon"])
        plt.title(f"Comparaison des {metric} - Base vs Optimisé", fontsize=14)
        plt.ylabel(metric)
        plt.xlabel("Modèle")
        plt.legend(title="Version")
        plt.grid(axis="y", linestyle="--", alpha=0.7)

        # Sauvegarde du graphique
        filename = f"comparaison_{metric}.png"
        plt.savefig(filename)
        mlflow.log_artifact(filename)
        plt.show()

    # Log des scores finaux dans MLflow
    for _, row in df_perf.iterrows():
        prefix = f"{row['Modèle']}_{row['Version']}"
        mlflow.log_metric(f"{prefix}_MAE", row["MAE"])
        mlflow.log_metric(f"{prefix}_RMSE", row["RMSE"])
        mlflow.log_metric(f"{prefix}_R2", row["R²"])

from sklearn.ensemble import HistGradientBoostingRegressor
import mlflow
import mlflow.sklearn
import joblib

# --- Construction et entraînement du meilleur modèle ---
best_model = build_pipeline(
    HistGradientBoostingRegressor(
        **study.best_params,
        random_state=42
    )
)
best_model.fit(X_train, y_train)

# --- Démarrage du run MLflow pour la sauvegarde finale ---
with mlflow.start_run(run_name="Modèle_final_sauvegardé"):
    # Log des hyperparamètres choisis par Optuna
    mlflow.log_params(study.best_params)

    # Log du modèle dans MLflow (version serialisée + interface DAGsHub)
    mlflow.sklearn.log_model(best_model, artifact_path="best_model")

    # Sauvegarde locale avec joblib
    joblib.dump(best_model, "modele_final_gradientboosting.pkl")

    # Log du fichier .pkl comme artefact dans MLflow
    mlflow.log_artifact("modele_final_gradientboosting.pkl")

    # Optionnel : log manuel des performances finales
    preds = best_model.predict(X_test)
    mlflow.log_metric("MAE", mean_absolute_error(y_test, preds))
    mlflow.log_metric("RMSE", np.sqrt(mean_squared_error(y_test, preds)))
    mlflow.log_metric("R2", r2_score(y_test, preds))

"""- Sélectionne le GradientBoosting optimisé.
- Entraîne sur tout le train.
- Sauvegarde avec joblib.

"""

import matplotlib.pyplot as plt

# Après avoir entraîné ton modèle
preds = best_model.predict(X_test)

# Courbe prédictions vs réalité
plt.scatter(y_test, preds, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Valeurs réelles")
plt.ylabel("Valeurs prédites")
plt.title("Prédictions vs Réalité")
plt.show()

"""- Courbes prédictions vs réalité.
- Courbes des résidus.


"""

import shutil

# Crée un zip du dossier mlruns
shutil.make_archive("mlruns", 'zip', "mlruns")